# deep-learning

Exercise projects on basic deep learning algorithms

## ex01_Python Basics with Numpy

- Be able to use iPython Notebooks
- Be able to use numpy functions and numpy matrix/vector operations
- Understand the concept of "broadcasting"
- Be able to vectorize code

## ex02_Logistic Regression as a Neural Network

- Build the general architecture of a learning algorithm, including:
  - Initializing parameters
  - Calculating the cost function and its gradient
  - Using an optimization algorithm (gradient descent)
- Gather all three functions above into a main model function, in the right order

## ex03_Planar Data Classification with One Hidden Layer

- Implement a 2-class classification neural network with a single hidden layer
- Use units with a non-linear activation function, such as tanh
- Compute the cross entropy loss
- Implement forward and backward propagation

## ex04_Building your Deep Neural Network: Step by Step

- Use non-linear units like ReLU to improve your model
- Build a deeper neural network (with more than 1 hidden layer)
- Implement an easy-to-use neural network class

## ex05_Deep Neural Network for Image Classification: Application

- Build and apply a deep neural network to supervised learning

## ex06_Initialization

- Speed up the convergence of gradient descent
- Increase the odds of gradient descent converging to a lower training (and generalization) error

## ex07_Regularization

- Use regularization in your deep learning models

## ex08_Gradient Checking

- Implement and use gradient checking

## ex09_Optimization Methods

- Speed up learning and get a better final value for the cost function using more advanced optimization methods

## ex10_TensorFlow Tutorial

- Initialize variables
- Start your own session
- Train algorithms
- Implement a Neural Network