# deep-learning

Exercise projects on basic deep learning algorithms

## ex1_Python Basics with Numpy

- Be able to use iPython Notebooks
- Be able to use numpy functions and numpy matrix/vector operations
- Understand the concept of "broadcasting"
- Be able to vectorize code

## ex2_Logistic Regression as a Neural Network

- Build the general architecture of a learning algorithm, including:
  - Initializing parameters
  - Calculating the cost function and its gradient
  - Using an optimization algorithm (gradient descent)
- Gather all three functions above into a main model function, in the right order

## ex3_Planar Data Classification with One Hidden Layer

- Implement a 2-class classification neural network with a single hidden layer
- Use units with a non-linear activation function, such as tanh
- Compute the cross entropy loss
- Implement forward and backward propagation

## ex4_Building your Deep Neural Network: Step by Step

- Use non-linear units like ReLU to improve your model
- Build a deeper neural network (with more than 1 hidden layer)
- Implement an easy-to-use neural network class

## ex5_Deep Neural Network for Image Classification: Application

- Build and apply a deep neural network to supervised learning

## ex6_Initialization

- Speed up the convergence of gradient descent
- Increase the odds of gradient descent converging to a lower training (and generalization) error

## ex7_Regularization

- Use regularization in your deep learning models

## ex8_Gradient Checking

- Implement and use gradient checking

## ex9_Optimization Methods

- Speed up learning and get a better final value for the cost function using more advanced optimization methods